{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 2 is smaller than n_iter=5. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'tol': 0.0001, 'solver': 'adam', 'max_iter': 1000, 'learning_rate': 'constant', 'hidden_layer_sizes': (50,), 'batch_size': 32, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Best Cross-Validation Score: 0.835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Reduce the size of the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.0001],\n",
    "    'learning_rate': ['constant'],\n",
    "    'batch_size': [32],\n",
    "    'tol': [1e-4],\n",
    "    'max_iter': [1000], \n",
    "}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=MLPClassifier(random_state=42),\n",
    "                                   param_distributions=param_grid,\n",
    "                                   n_iter=5,  # Reduce the number of iterations\n",
    "                                   cv=3,  # Reduce the number of cross-validation folds\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "# Fitting the RandomizedSearchCV object\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_mlp = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Classifier  Accuracy  Precision    Recall  F1 Score\n",
      "0  Support Vector Machine  0.816667   0.807452  0.816667  0.810937\n",
      "1           Decision Tree  0.750000   0.771307  0.750000  0.758810\n",
      "2           Random Forest  0.833333   0.828993  0.833333  0.830877\n",
      "3                CatBoost  0.825000   0.827499  0.825000  0.826183\n",
      "4                AdaBoost  0.833333   0.828993  0.833333  0.830877\n",
      "5                 XGBoost  0.800000   0.805745  0.800000  0.802628\n",
      "6             Naive Bayes  0.783333   0.613611  0.783333  0.688162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"weatherAUS.csv\")\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "y=df['RainToday'].to_numpy()\n",
    "y=y[:600]\n",
    "X=df[['MinTemp','MaxTemp']].to_numpy()\n",
    "X=X[:600]\n",
    "# Impute missing values with the mean of the respective feature\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "label_imputer = SimpleImputer(strategy='most_frequent')\n",
    "y = label_imputer.fit_transform(y.reshape(-1, 1))  # Reshape y to be a 2D array\n",
    "# Flatten y back to 1D array\n",
    "y = y.flatten()\n",
    "# Encode labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(logging_level='Silent'),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Train classifiers and make predictions\n",
    "results = {'Classifier': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1 Score': []}\n",
    "for clf_name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    results['Classifier'].append(clf_name)\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Precision'].append(precision)\n",
    "    results['Recall'].append(recall)\n",
    "    results['F1 Score'].append(f1)\n",
    "\n",
    "# Convert labels back to original string labels for tabulation\n",
    "y_test = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Create a dataframe to tabulate the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
